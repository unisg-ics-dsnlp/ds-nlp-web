<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  






























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>DS-NLP Lab</title>

<link rel="icon" href="/preview/pr-30/images/icon.png">

<meta name="title" content="">
<meta name="description" content="Chair of Siegfried Handschuh | Data Science in Natural Language Processing. Chair of Siegfried Handschuh for Data Science in Natural Language Processing at the University of St. Gallen (HSG).">

<meta property="og:title" content="">
<meta property="og:site_title" content="DS-NLP Lab">
<meta property="og:description" content="Chair of Siegfried Handschuh | Data Science in Natural Language Processing. Chair of Siegfried Handschuh for Data Science in Natural Language Processing at the University of St. Gallen (HSG).">
<meta property="og:url" content="/preview/pr-30">
<meta property="og:image" content="/preview/pr-30/images/ICS_HSG-LogoWithWhiteBackground.png">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="">
<meta property="twitter:description" content="Chair of Siegfried Handschuh | Data Science in Natural Language Processing. Chair of Siegfried Handschuh for Data Science in Natural Language Processing at the University of St. Gallen (HSG).">
<meta property="twitter:url" content="/preview/pr-30">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/preview/pr-30/images/ICS_HSG-LogoWithWhiteBackground.png">


  <meta property="og:type" content="website">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "WebSite",
    
    "name": "",
    "description": "Chair of Siegfried Handschuh | Data Science in Natural Language Processing. Chair of Siegfried Handschuh for Data Science in Natural Language Processing at the University of St. Gallen (HSG).",
    "headline": "",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "/preview/pr-30/images/icon.png" }
    },
    "url": "/preview/pr-30"
  }
</script>

<link rel="alternate" type="application/rss+xml" href="/preview/pr-30/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.7.0/css/all.css" rel="stylesheet" media="none" onload="this.removeAttribute('media'); this.onload = null;">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.7.0/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/preview/pr-30/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/all.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/background.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/body.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/button.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/card.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/code.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/details.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/float.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/font.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/form.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/header.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/image.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/link.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/list.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/main.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/section.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/table.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/preview/pr-30/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/preview/pr-30/_scripts/anchors.js"></script>

  <script src="/preview/pr-30/_scripts/dark-mode.js"></script>

  <script src="/preview/pr-30/_scripts/fetch-tags.js"></script>

  <script src="/preview/pr-30/_scripts/search.js"></script>

  <script src="/preview/pr-30/_scripts/site-search.js"></script>

  <script src="/preview/pr-30/_scripts/table-wrap.js"></script>

  <script src="/preview/pr-30/_scripts/tooltip.js"></script>


</head>

  <body>
    







<header class="background" style="--image: url('/preview/pr-30/images/background.jpg')" data-dark="true" data-big>
  <a href="/preview/pr-30/" class="home">
    
      <span class="logo">
        
          <?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 26.0.1, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<svg version="1.1" id="Logo" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewbox="0 0 90 100" style="enable-background:new 0 0 90 100;" xml:space="preserve">
<style type="text/css">
	.st0{fill:#00802F;}
</style>
<g>
	<path class="st0" d="M90,70L54.6,57.12c-1.22-0.44-2.15-1.45-2.49-2.71l-0.6-2.19c-0.62-2.27,0.85-4.58,3.16-4.99L90,41V70z
		 M40.96,56.63L38.6,54c-1.26-1.4-3.34-1.73-4.97-0.79L8.1,67.94l4.46,25.28l9.96,0.87L41.46,61.3
		C42.32,59.8,42.12,57.91,40.96,56.63z M35.91,27.5c-0.51-1.48-1.84-2.52-3.4-2.66L0,22l7.05,39.97l32.54-18.79
		c0.83-0.48,1.2-1.48,0.88-2.38c-0.2-0.55-0.63-0.99-1.18-1.19c-2.5-0.9-4.29-3.3-4.29-6.12c0-1.02,0.24-1.99,0.66-2.85
		C36.14,29.67,36.26,28.54,35.91,27.5 M90,0L41.73,22.51c-1.03,0.48-1.5,1.67-1.08,2.73l0.21,0.52c0.29,0.73,0.96,1.2,1.73,1.34
		c2.03,0.35,3.87,1.65,4.81,3.66c1.1,2.36,0.66,5.04-0.91,6.92c-0.38,0.45-0.49,1.07-0.27,1.61c0.32,0.8,1.22,1.21,2.03,0.91L90,25
		V0z M56.12,65.28c-3.85-2.7-9.19-1.51-11.53,2.57L29.18,94.68L90,100V89L56.12,65.28z"></path>
</g>
</svg>

        
      </span>
    
    
      <span class="title-text" data-tooltip="Home">
        
          <span class="title">DS-NLP Lab</span>
        
        
          <span class="subtitle">Chair of Siegfried Handschuh | Data Science in Natural Language Processing</span>
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/preview/pr-30/research/" data-tooltip="Published works">
          Research
        </a>
      
    
      
        <a href="/preview/pr-30/books/" data-tooltip="Published books">
          Books
        </a>
      
    
      
        <a href="/preview/pr-30/projects/" data-tooltip="Software, datasets, and more">
          Projects
        </a>
      
    
      
        <a href="/preview/pr-30/team/" data-tooltip="About our team">
          Team
        </a>
      
    
      
        <a href="/preview/pr-30/blog/" data-tooltip="Musings and miscellany">
          Blog
        </a>
      
    
      
        <a href="/preview/pr-30/contact/" data-tooltip="Email, address, and location">
          Contact
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - filter out blank sections
-->






  
  
  

  <section class="background" data-size="page">
    <!-- # DS-NLP Lab Blog and Research Website -->

<p>The Data Science and Natural Language Processing (DS-NLP) Lab at the University of St. Gallen, led by Professor Siegfried Handschuh, pioneers research at the intersection of artificial intelligence, data science, and Natural Language Processing technologies. Our team focuses on advancing knowledge extraction, semantic representation, Argumentation and the societal impacts of AI-driven language systems. Through innovative projects and scholarly publications, we aim to bridge the gap between complex data and meaningful human understanding.</p>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  <background></background>
  <dark></dark>
  <size></size>
-->

<h2 id="latest-blog-posts">Latest Blog Posts</h2>

<div class="post-excerpt-container">
  <div class="post-excerpt">
    
    
    

    
      <a href="/preview/pr-30/2025/10/07/acm-icaif-2025.html" class="post-excerpt-image" aria-label="Can AI Read Like a Financial Analyst A New Study Puts Top LLMs to the Test">
        <img src="/preview/pr-30/images/posts/2025-10-07-acm-icaif-2025.jpg" alt="Can AI Read Like a Financial Analyst A New Study Puts Top LLMs to the Test" loading="lazy" onerror="this.src = '/preview/pr-30/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="post-excerpt-text">
      <a href="/preview/pr-30/2025/10/07/acm-icaif-2025.html">Can AI Read Like a Financial Analyst? A New Study Puts Top LLMs to the Test</a>

      <div class="post-info">
  
    
    
      
      
        <span data-tooltip="Author">
          <i class="icon fa-solid fa-feather-pointed"></i>
          <span>jan spörer</span>
        </span>
      
    
  

  
  

  
    <span data-tooltip="Originally published on">
      <i class="icon fa-regular fa-calendar"></i>
      <span>October 07, 2025</span>
    </span>
  

  
    <span data-tooltip="Last updated on">
      <i class="icon fa-solid fa-clock-rotate-left"></i>
      <span>November 10, 2025</span>
    </span>
  
</div>


  


  <div class="tags">
    
      <a href='/preview/pr-30/blog?search="tag:%20finance"' class="tag" data-tooltip='Show items with the tag "finance"'>
        finance
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20finance-and-ai"' class="tag" data-tooltip='Show items with the tag "finance-and-ai"'>
        finance-and-ai
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20annual-reports"' class="tag" data-tooltip='Show items with the tag "annual-reports"'>
        annual-reports
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20large-language-models"' class="tag" data-tooltip='Show items with the tag "large-language-models"'>
        large-language-models
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20machine-learning"' class="tag" data-tooltip='Show items with the tag "machine-learning"'>
        machine-learning
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20gemini-2.5-pro"' class="tag" data-tooltip='Show items with the tag "gemini-2.5-pro"'>
        gemini-2.5-pro
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20retrieval-augmented-generation"' class="tag" data-tooltip='Show items with the tag "retrieval-augmented-generation"'>
        retrieval-augmented-generation
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20graph-rag"' class="tag" data-tooltip='Show items with the tag "graph-rag"'>
        graph-rag
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20graphs"' class="tag" data-tooltip='Show items with the tag "graphs"'>
        graphs
      </a>
    
  </div>





      
      
      <p data-search="A New Frontier for AI in Finance: Reading Annual ReportsFor financial analysts, wading through hundreds of pages of dense annual reports is a fundamental, time-consuming part of the job. Investors read these reports directly, or read secondary equity research written by financial analysts 2 . These documents, which can exceed 700 pages, are packed with financial data, regulatory disclosures, and strategic narratives that drive investment decisions. The complexity is immense; analysts must connect hundreds of financial metrics, temporal data, and subtle narrative cues to form a coherent investment thesis and use the reports to set stock price targets 5, 11 and give investment recommendations 4, 27 .This critical task seems ripe for AI automation, but a key question has remained: can AI systems truly comprehend these documents with the reliability required for high-stakes financial decisions Our new paper, Can AI Read Like a Financial Analyst , tackles this question head-on by conducting the most comprehensive open evaluation of leading AI models on financial document comprehension.Putting AI to the Test with Financial TouchstoneTo create a fair and unbiased evaluation, we first had to address a major concern in AI research: training data contamination. We needed to ensure the models we tested had never seen our evaluation questions before.To do this, we introduced Financial Touchstone, a new large-scale benchmark guaranteed to be unseen by the models. It s one of the largest and most diverse datasets of its kind: 480 international annual reports from 22 countries, ensuring a global scope beyond just the US. 2,878 question-context-answer triplets, focusing on the types of questions professional analysts ask most frequently 25 . Over 83 million tokens of high-quality financial text, primarily from the years 2021-2023.Using this benchmark, we tested eleven of the world s most advanced language models, including Google s Gemini 2.5 Pro, OpenAI s o3, Anthropic s Claude 4 Opus, and xAI s Grok 4. To handle the immense length of the documents, we used a standard Retrieval-Augmented Generation RAG architecture 15 , which first finds relevant passages and then feeds them to the model to generate an answer.The Surprising Bottleneck: It s Not Reasoning, It s RetrievalOur findings fundamentally reframe the challenge of automating financial analysis. The results show that the top reasoning models are remarkably capable of understanding complex financial text when given the correct information.Google s Gemini 2.5 Pro led the pack, achieving an impressive 91.6 accuracy with a hallucination rate of just 3.2 . This performance actually surpasses the human baseline for accuracy 84.8 we established in our study, though humans still make fewer unfounded claims 2.8 hallucination rate . Models like OpenAI s o3 and Anthropic s Claude 4 models also performed exceptionally well.However, this high accuracy comes with a huge caveat. The primary bottleneck is not the model s comprehension ability, but the initial information retrieval step.When the RAG system failed to find and provide the correct context from the annual report, model accuracy plummeted to a staggering 0.2 . Model Performance Excluding Retriever Errors . Top reasoning models like Gemini 2.5 Pro achieve accuracy surpassing the human baseline when provided with the correct context. Our failure analysis revealed that a shocking two-thirds 66.5 of all errors stemmed from the retriever failing to find the needle in the haystack 21 . In contrast, true model comprehension errors accounted for only 3 of failures. This demonstrates that future progress hinges more on solving the challenge of targeted information retrieval than on incremental improvements in model reasoning alone. Failure analysis by question type. The retriever struggles most with broad questions like key financials, where information is often scattered across many pages. As we have already seen in our prior research 25 , models often have low error overlap, offering promising potential for LLM ensembles. LLMs can thus correct each other in some cases. This further strengthens the generative part of RAG pipelines, while making the need for better retrieval even more pressing. Multidimensional Performance Comparison of All Models: Each spider chart shows accuracy for industries, years, regions, and overall groundedness i.e., inverse hallucination rate . Each circle layer is a 25 step. Key Insights and Future DirectionsOur study provides a clear roadmap for the future of AI in financial analysis. Retrieval is the new frontier. The central challenge isn t asking Can AI read but rather, Can AI find what it needs to read . Building better retrievers perhaps using advanced methods like GraphRAG 12 is the most critical next step. Reasoning models are essential. There is a significant performance gap between reasoning and non-reasoning models. The top models deliver a 15 percentage point uplift in accuracy and are far better at avoiding hallucinations, making them a prerequisite for reliable financial tools. Model ensembling shows promise. We found very low agreement between the different top models. This suggests that production systems could achieve higher reliability by combining the outputs of several diverse models, such as an ensemble of Gemini 2.5 Pro, OpenAI s o3, and Anthropic s Claude Sonnet 4. ConclusionSo, can AI read like a financial analyst Our research provides a qualified yes but only if it s given the right pages. The reasoning capabilities of today s frontier models are largely sufficient for the task.The evidence is clear: the most direct path to unlocking the next generation of AI in finance is to solve the fundamental challenge of information retrieval. With the accuracy and reliability demonstrated by the top models, AI is poised to enhance trust and transparency in equity research, helping to address long-standing issues of analyst bias and conflicts of interest 20 .To accelerate this effort, we are making the complete Financial Touchstone dataset, evaluation framework, and source code publicly available upon publication.Link to the Paper no title info no publisher info nbsp; nbsp; no date info nbsp; nbsp; no id info References 2 Asquith, P., Mikhail, M., amp; Au, A. 2005 . Information Content of Equity Analyst Reports. Journal of Financial Economics, 75 2 , 245-282. 4 Barber, B., Lehavy, R., McNichols, M., amp; Trueman, B. 2001 . Can Investors Profit From the Prophets Security Analyst Recommendations and Stock Returns. The Journal of Finance, 56 2 , 531-563. 5 Bonini, S., Zanetti, L., Bianchini, R., amp; Salvi, A. 2010 . Target Price Accuracy in Equity Research. Journal of Business Finance amp; Accounting, 37 9-10 , 1177-1217. 11 Gleason, C., Johnson, B., amp; Li, H. 2013 . Valuation Model Use and the Price Target Performance of Sell-Side Equity Analysts. Contemporary Accounting Research, 30 1 , 80-115. 12 Han, H., Shomer, H., Wang, Y., Lei, Y., Guo, K., Hua, Z., Long, B., Liu, H., amp; Tang, J. 2025 . RAG vs. GraphRAG: A Systematic Evaluation and Key Insights. arXiv. 15 Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W.-T., Rocktäschel, T., Riedel, S., amp; Kiela, D. 2020 . Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. Advances in Neural Information Processing Systems NIPS , 33, 9459-9474. 20 Michaely, R., amp; Womack, K. 1999 . Conflict of Interest and the Credibility of Underwriter Analyst Recommendations. The Review of Financial Studies, 12 4 , 653-686. 21 Nelson, E., Kollias, G., Das, P., Chaudhury, S., amp; Dan, S. 2024 . Needle in the Haystack for Memory Based Large Language Models. ICML 2024 Workshop-Next Generation of Sequence Modeling Architectures. 25 Pop, A., amp; Spörer, J. 2025 . Identification of the Most Frequently Asked Questions in Financial Analyst Reports to Automate Equity Research Using Llama 3 and GPT-4. IEEE Swiss Data Science Conference SDS . 27 Womack, K. 1996 . Do Brokerage Analysts Recommendations Have Investment Value The Journal of Finance, 51 1 , 137-167.">
        A New Frontier for AI in Finance: Reading Annual Reports

      </p>
    </div>
  </div>
</div>

<div class="post-excerpt-container">
  <div class="post-excerpt">
    
    
    

    
      <a href="/preview/pr-30/2025/09/24/SDS2025-2.html" class="post-excerpt-image" aria-label="Identification of the Most Frequently Asked Questions in Financial Analyst Reports to Automate Equity Research Using Llama 3 and GPT-4">
        <img src="/preview/pr-30/images/posts/SDS-2025-2-cover.png" alt="Identification of the Most Frequently Asked Questions in Financial Analyst Reports to Automate Equity Research Using Llama 3 and GPT-4" loading="lazy" onerror="this.src = '/preview/pr-30/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="post-excerpt-text">
      <a href="/preview/pr-30/2025/09/24/SDS2025-2.html">Identification of the Most Frequently Asked Questions in Financial Analyst Reports to Automate Equity Research Using Llama 3 and GPT-4</a>

      <div class="post-info">
  
    
    
      
      
        <span data-tooltip="Author">
          <i class="icon fa-solid fa-feather-pointed"></i>
          <span>jan spörer</span>
        </span>
      
    
  

  
  

  
    <span data-tooltip="Originally published on">
      <i class="icon fa-regular fa-calendar"></i>
      <span>September 24, 2025</span>
    </span>
  

  
    <span data-tooltip="Last updated on">
      <i class="icon fa-solid fa-clock-rotate-left"></i>
      <span>November 10, 2025</span>
    </span>
  
</div>


  


  <div class="tags">
    
      <a href='/preview/pr-30/blog?search="tag:%20finance"' class="tag" data-tooltip='Show items with the tag "finance"'>
        finance
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20finance-and-ai"' class="tag" data-tooltip='Show items with the tag "finance-and-ai"'>
        finance-and-ai
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20annual-reports"' class="tag" data-tooltip='Show items with the tag "annual-reports"'>
        annual-reports
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20equity-research"' class="tag" data-tooltip='Show items with the tag "equity-research"'>
        equity-research
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20machine-learning"' class="tag" data-tooltip='Show items with the tag "machine-learning"'>
        machine-learning
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20gpt-4"' class="tag" data-tooltip='Show items with the tag "gpt-4"'>
        gpt-4
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20llama-3"' class="tag" data-tooltip='Show items with the tag "llama-3"'>
        llama-3
      </a>
    
  </div>





      
      
      <p data-search="The Structure of Financial Equity ResearchFinancial equity research reports ERRs are a means to communicate buy and sell recommendations about individual stocks. Banks and independent research firms write those reports to convince their clients to buy or sell stocks earning the banks a brokerage commission , or to receive direct compensation for their research. Typically, financial experts, so-called analysts, cover a basket of stock-listed companies from one or two industries over a long period of time, and update their ERRs whenever important news come out often after quarterly reports 36 .ERRs typically contain a stock price target e.g., a forecasted stock price of 250 per share within the next 12 months as well as a buy, hold, or sell recommendation.The banks clients and the general market use these reports to support investment decisions in the stocks and, to a lesser extent, bonds of these companies.Financial Text One Hard Nut to Crack for AutomationRelevanceIn the financial literature, ERRs are established as important sources of information 44, 45, 46, 47, 48 . They offer some empirically validated insights into the future stock performance of firms 49 , so they may indeed help investors to make decisions.Issues With Financial Equity Research: Bias and CostBut a problem remains: Many reports are written by banks, and banks have an inherent interest in earning commissions from trades placed by their clients. This means they often want to convince potential clients to buy stocks, possibly introducing a reluctance to publish negative coverage 42, 43 . 36 found that only 0.5 of all reports contained sell recommendations before the dot-com bubble burst. Prior research showed less extreme results, with 14 sell recommendations between 1989 and 1991 49 , but the direction is still clear: ERRs seem to be a tad to positive and not entirely unbiased.Another issue with ERRs are cost. As our results below show, much of equity research is just a presentation of financials. Overall, ERRs follow a mechanistic, descriptive pattern. It is thus questionable if significant human input is warranted and useful. Given the concerns around biasedness in equity research, the field may thus benefit from further automation. Our paper provides the groundwork for systematic automation of equity research.The Structure of Equity ResearchWhile research about the relevance and biasedness of equity reports is plentiful, there is little understanding about what types of contents these reports cover and to what extent the context might be automated. So far, there was no systematic research into the structure of financial equity research reports so that is where our research comes in. Based on 72 English equity research reports written between 2018 and 2022, covering a broad range of authors banks and covered companies, we empirically uncover how equity analysts write.Let s start with the basics: Equity research reports are consistently short. Unlike annual reports, which usually have hundreds of pages, equity research is short and concise, and reports with 20 pages are long outliers already.The figures below illustrate that most reports have between 4 and 9 pages, and they do not contain more than 120 statements. Distribution of page counts and statement counts of equity research reports. Most reports have between 4--9 pages and 30--120 statements. Including appendices. Different types of information are systematically presented with different modes of display. Financial information is often structured enough to be displayed in tables and diagrams, while company and market overviews are usually verbal. How Do Banks and Independent Analysts Present Their Analyses In our study Pop amp; Spörer 2025 , we found that text and tables are the dominant ways of conveying information in equity research reports. Diagrams, which often come in the form of stock price charts, are less relevant overall. Custom diagrams that show complex business relationships, product specifications, or market dynamics, are an absolute exception.Textual and tabular statement can often be expressed in various ways, and analysts switch between textual and tabular modes. Different banks tend to have different styles. Some make heavy use of tables, while others present almost all information in text form. This heavy reliance on text and tables is a potential for LLMs, as text and tables are the native domain of language models. Today s language models can write tables in Markdown or in other machine-readable formats. There is significant overlap between presentation modes for the same statements. Textual and tabular representation modes are dominant. Analysts have a strong bias in favor of the type of information that they know best: Financials. This is reflected in the following diagram, which shows that most statements fall into the Financials category. As mentioned above, analysts usually do not take the time to present product-specific diagrams or to display market dynamics or supply chains in graphical form. The category Product illustrates. Statements about the income statement profit amp; loss -- P amp;L are the most frequent question subcategory in our typology. Most of the other top subcategories also fall in the Financials subcategory. An exception is the Stock Price subcategory, which is the second most important subcategory by frequency. How Large is the Dent That LLMs Can Make in Automating Equity Research According to our research, already 55 of the statements from equity research reports are automatable, even without any use of AI LLMs. This is due to the comprehensive data coverage that financial databases such as Bloomberg provide. Executive changes, financials, and subsidiary structures are readily available in structured format in these databases.Thus, to evaluate the automation potential that LLMs can still have, we substracted this 55 from the overall pie, and ended up with 30 of automation potential for LLMs. Thus, only 15 of statements in ERRs cannot be automated.Of these 30 , 26 percentage points were answered correctly by GPT-4, and 27 percentage points were answered correctly by Llama-3. The error rate is reduced when a perfect ensemble of these two models is assumed, as we show below. Language models can close a gap that financial databases leave open. Still, we think that human input is still required, as we assume non-fact based statements opinions and strategic outlooks cannot be automated by LLMs. Potential for Model EnsemblesWe found that GPT-4 and Llama-3 complement each other. In our small-scale analysis, when one of the models fails to answer a question correctly, the other model almost always is able to help out. This result shows that there is potential in multi-AI or multi-agent systems that outperform single-model inference. Ensembles of GPT-4 and Llama-3 have high potential as they show little error overlap. ConclusionThe study shows some patterns in equity research worth pointing out: Analysts usually do not create custom diagrams that deep-dive into product specifications, distribution or supply chains, market structures, or other complex relationships that underly the covered firms business. In fact, only 15 of the statements financial analysts make are hard to automate by LLMs in principle, as these represent strategic outlooks or opinions. Thus, the automation potential of equity research is high, as their human touch is already minuscle today. Most of the statements in financial report relate to financial information -- which can already be found in financial databases and does not require LLMs to be extracted. We still need to caution that analysts perform important roles that LLMs will not be able to replicate. For example, they personally meet management teams and may get subtle clues about the confidence and capabilities of these managers in these meetings. OutlookToday s ERRs heavily focus on financials. This probably arises from the skill set of their authors. Most financial analysts have degrees in business and finance, and these analysts are usually no product or service experts in the industries that they cover. LLMs offer potential for more holistic coverage that takes product and service quality of the covered firms into account, introducing an underappreciated aspect to equity research.Link to the Paper Identification of the Most Frequently Asked Questions in Financial Analyst Reports to Automate Equity Research Using Llama 3 and GPT-4 Adria Pop, Jan Spörer 2025 IEEE Swiss Conference on Data Science SDS nbsp; nbsp; 26 Jun 2025 nbsp; nbsp; doi:10.1109 SDS66131.2025.00025 This research dissects financial equity research reports ERRs by systematically mapping their content into categories. There is insufficient empirical analysis of the questions answered in ERRs. In particular, it is not understood how frequently certain information appears, what information is considered essential, and what information requires human judgment to distill into an ERR. The study analyzes 72 ERRs sentence-by-sentence, classifying their 4964 sentences into 169 unique question archetypes. We did not predefine the questions but derived them solely from the statements in the ERRs. This approach provides an unbiased view of the content of the observed ERRs. Subsequently, we used public corporate reports to classify the questions potential for automation. Answers were labeled text-extractable if the answers to the question were accessible in corporate reports. 75.15 of the questions in ERRs can be automated using text extraction from text sources. Those automatable questions consist of 51.91 text-extractable suited to processing by large language models, LLMs and 24.24 database-extractable questions. Only 24.85 of questions require human judgment to answer. We empirically validate, using Llama-3-70B and GPT-4-turbo-2024-04-09 that recent advances in language generation and infor- mation extraction enable the automation of approximately 80 of the statements in ERRs. Surprisingly, the models complement each other s strengths and weaknesses well, indicating strong ensemble potential. The research confirms that the current writing process of ERRs can likely benefit from additional automation, improving quality and efficiency. The research thus allows us to quantify the potential impacts of introducing large language models in the ERR writing process. The full question list, including the archetypes and their frequency, are available online link removed to preserve anonymity . DOI IEEE financial-ai annual-reports equity-research machine-learning gpt-4 llama-3 References 1 Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., et al. 2020 . Language Models Are Few-Shot Learners. Advances in Neural Information Processing Systems NeurIPS . 2 Devlin, J., Chang, M.-W., Lee, K., amp; Toutanova, K. 2019 . BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies NAACL-HLT . 3 Fawcett, T. 2006 . Introduction to Receiver Operator Curves. Pattern Recognition Letters. 4 Gilbert, E. 2014 . VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text. International Conference on Weblogs and Social Media ICWSM . 5 Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., amp; Iwasawa, Y. 2022 . Large Language Models Are Zero-Shot Reasoners. Advances in Neural Information Processing Systems NeurIPS . 6 Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., amp; Neubig, G. 2023 . Pre-Train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. ACM Computing Surveys. 7 Maia, M., Handschuh, S., Freitas, A., Davis, B., McDermott, R., Zarrouk, M., amp; Balahur, A. 2018 . WWW 18 Open Challenge: Financial Opinion Mining and Question Answering. Companion Proceedings of the Web Conference. 8 Malo, P., Sinha, A., Korhonen, P., Wallenius, J., amp; Takala, P. 2014 . Good Debt or Bad Debt: Detecting Semantic Orientations in Economic Texts. Journal of the Association for Information Science and Technology. 9 Liu, Z., Huang, D., Huang, K., Li, Z., amp; Zhao, J. 2021 . FinBERT: A Pre-Trained Financial Language Representation Model for Financial Text Mining. International Conference on Artificial Intelligence. 10 Woodford, M. 2005 . Central Bank Communication and Policy Effectiveness. National Bureau of Economic Research, Cambridge, MA, USA. 11 Hansen, S., McMahon, M., amp; Tong, M. 2019 . The Long-Run Information Effect of Central Bank Communication. Journal of Monetary Economics. 12 Araci, D. 2019 . FinBERT: Financial Sentiment Analysis with Pre-trained Language Models. arXiv. 13 Peters, M., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., amp; Zettlemoyer, L. 2018 . Deep Contextualized Word Representations. Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies NAACL-HLT . 14 Niklaus, C., Freitas, A., amp; Handschuh, S. 2022 . Shallow Discourse Parsing for Open Information Extraction and Text Simplification. Workshop on Computational Approaches to Discourse, International Conference on Computer Linguistics. 15 Chatterjee, N., amp; Agarwal, R. 2023 . Studying the Effect of Syntactic Simplification on Text Summarization. IETE Technical Review. 16 Cetto, M., Niklaus, C., Freitas, A., amp; Handschuh, S. 2018 . Graphene: A Context-Preserving Open Information Extraction System. International Conference on Computational Linguistics: System Demonstrations. 17 Abdel-Nabi, H., Awajan, A., amp; Ali, M. 2023 . Deep Learning-Based Question Answering: A Survey. Knowledge and Information Systems. 18 Izacard, G., Lewis, P., Lomeli, M., Hosseini, L., Petroni, F., Schick, T., Dwivedi-Yu, J., Joulin, A., Riedel, S., amp; Grave, E. 2022 . Atlas: Few-Shot Learning with Retrieval Augmented Language Models. arXiv. 19 Guu, K., Lee, K., Tung, Z., Pasupat, P., amp; Chang, M.-W. 2020 . REALM: Retrieval-Augmented Language Model Pre-Training. International Conference on Machine Learning ICML , Proceedings of Machine Learning Research PMLR . 20 Karpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., amp; Yih, W.-T. 2020 . Dense Passage Retrieval for Open-Domain Question Answering. Conference on Empirical Methods in Natural Language Processing EMNLP . 21 Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W.-T., Rocktäschel, T., Riedel, S., amp; Kiela, D. 2020 . Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. Advances in Neural Information Processing Systems. 22 Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozière, B., Goyal, N., Hambro, E., Azhar, F., et al. 2023 . LLaMA: Open and Efficient Foundation Language Models. arXiv. 23 Press, O., Smith, N., amp; Lewis, M. 2022 . Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation. International Conference on Learning Representations ICLR . 24 Antony, D., Abhishek, S., Singh, S., Kodagali, S., Darapaneni, N., Rao, M., Paduri, A. R., amp; Bandalakunta Gururajarao, S. 2023 . A Survey of Advanced Methods for Efficient Text Summarization. IEEE Computing and Communication Workshop and Conference CCWC . 25 Chen, S., Wong, S., Chen, L., amp; Tian, Y. 2023 . Extending Context Window of Large Language Models via Positional Interpolation. arXiv. 26 Wu, S., Irsoy, O., Lu, S., Dabravolski, V., Dredze, M., Gehrmann, S., Kambadur, P., Rosenberg, D., amp; Mann, G. 2023 . BloombergGPT: A Large Language Model for Finance. arXiv. 27 Fama, E., amp; French, K. 2018 . Choosing Factors. Journal of Financial Economics. 28 Fama, E., amp; French, K. 2015 . A Five-Factor Asset Pricing Model. Journal of Financial Economics. 29 Fama, E., amp; French, K. 1995 . Size and Book-to-Market Factors in Earnings and Returns. The Journal of Finance. 30 Fama, E. 1965 . The Behavior of Stock-Market Prices. The Journal of Business. 31 Fama, E., amp; French, K. 1992 . The Cross-Section of Expected Stock Returns. The Journal of Finance. 32 Carhart, M. 1997 . On Persistence in Mutual Fund Performance. The Journal of Finance. 33 Asness, C., Moskowitz, T., amp; Pedersen, L. 2013 . Value and Momentum Everywhere. The Journal of Finance. 34 Dyer, T., amp; Kim, E. 2021 . Anonymous Equity Research. Journal of Accounting Research. 35 Gleason, C., Johnson, B., amp; Li, H. 2013 . Valuation Model Use and the Price Target Performance of Sell-Side Equity Analysts. Contemporary Accounting Research. 36 Asquith, P., Mikhail, M., amp; Au, A. 2005 . Information Content of Equity Analyst Reports. Journal of Financial Economics. 37 Imam, S., Chan, J., amp; Shah, S. 2013 . Equity Valuation Models and Target Price Accuracy in Europe: Evidence From Equity Reports. International Review of Financial Analysis. 38 Arand, D., Kerl, A., amp; Walter, A. 2015 . When Do Sell-Side Analyst Reports Really Matter Shareholder Protection, Institutional Investors and the Informativeness of Equity Research. European Financial Management. 39 Bonini, S., Zanetti, L., Bianchini, R., amp; Salvi, A. 2010 . Target Price Accuracy in Equity Research. Journal of Business Finance amp; Accounting. 40 Twedt, B., amp; Rees, L. 2012 . Reading Between the Lines: An Empirical Examination of Qualitative Attributes of Financial Analysts Reports. Journal of Accounting and Public Policy. 41 Cheng, W., amp; Ho, J. 2017 . A Corpus Study of Bank Financial Analyst Reports: Semantic Fields and Metaphors. International Journal of Business Communication. 42 Mikhail, M., Walther, B., amp; Willis, R. 2004 . Do Security Analysts Exhibit Persistent Differences in Stock Picking Ability Journal of Financial Economics. 43 Barber, B., Lehavy, R., McNichols, M., amp; Trueman, B. 2001 . Can Investors Profit From the Prophets Security Analyst Recommendations and Stock Returns. The Journal of Finance. 44 Bjerring, J., Lakonishok, J., amp; Vermaelen, T. 1983 . Stock Prices and Financial Analysts Recommendations. The Journal of Finance. 45 Elton, E., Gruber, M., amp; Grossman, S. 1986 . Discrete Expectational Data and Portfolio Performance. The Journal of Finance. 46 Liu, P., Smith, S., amp; Syed, A. 1990 . Stock Price Reactions to the Wall Street Journal s Securities Recommendations. Journal of Financial and Quantitative Analysis. 47 Beneish, M. 1991 . Stock Prices and the Dissemination of Analysts Recommendation. Journal of Business. 48 Stickel, S. 1995 . The Anatomy of the Performance of Buy and Sell Recommendations. Financial Analysts Journal. 49 Michaely, R., amp; Womack, K. 1999 . Conflict of Interest and the Credibility of Underwriter Analyst Recommendations. The Review of Financial Studies. 50 Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ilić, S., Hesslow, D., Castagné, R., Luccioni, A. S., amp; Yvon, F. 2022 . Bloom: A 176b-Parameter Open-Access Multilingual Language Model. arXiv. 51 Rae, J., Borgeaud, S., Cai, T., Millican, K., Hoffmann, J., et al. 2022 . Scaling Language Models: Methods, Analysis amp; Insights from Training Gopher. arXiv. 52 Zhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M., Chen, S., Dewan, C., Diab, M., Li, X., amp; Lin, X. V. 2022 . OPT: Open Pre-Trained Transformer Language Models. arXiv. 53 Desislavov, R., Martínez-Plumed, F., amp; Hernández-Orallo, J. 2023 . Trends in AI Inference Energy Consumption: Beyond the Performance-vs-Parameter Laws of Deep Learning. Sustainable Computing: Informatics and Systems. 54 Chen, Z., Chen, W., Smiley, C., Shah, S., Borova, I., Langdon, D., Moussa, R., Beane, M., Huang, T.-H., Routledge, B., amp; Wang, W. Y. 2021 . FinQA: A Dataset of Numerical Reasoning over Financial Data. Conference on Empirical Methods in Natural Language Processing EMNLP . 55 Chen, Y., Fu, Q., Yuan, Y., Wen, Z., Fan, G., Liu, D., Zhang, D., Li, Z., amp; Xiao, Y. 2023 . Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models. Proceedings of the 32nd ACM International Conference on Information and Knowledge Management CIKM 23 . 56 Womack, K. 1996 . Do Brokerage Analysts Recommendations Have Investment Value The Journal of Finance. 57 Bradshaw, M., Brown, L., amp; Huang, K. 2013 . Do Sell-Side Analysts Exhibit Differential Target Price Forecasting Ability Review of Accounting Studies. 58 Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., et al. 2021 . Improving Language Models by Retrieving From Trillions of Tokens. International Conference on Machine Learning ICML , Proceedings of Machine Learning Research PMLR . 59 Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y. J., Madotto, A., amp; Fung, P. 2023 . Survey of Hallucination in Natural Language Generation. ACM Computing Surveys. 60 Zhu, F., Lei, W., Huang, Y., Wang, C., Zhang, S., Lv, J., Feng, F., amp; Chua, T.-S. 2021 . TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and Textual Content in Finance. Annual Meeting of the ACL and International Joint Conference on Natural Language Processing. 61 Coleman, B., Merkley, K., amp; Pacelli, J. 2022 . Human Versus Machine: A Comparison of Robo-Analyst and Traditional Research Analyst Investment Recommendations. The Accounting Review. 62 Thai, V. T., Davis, B., O Riain, S., O Sullivan, D., amp; Handschuh, S. 2008 . Semantically Enhanced Passage Retrieval for Business Analysis Activity. European Conference on Information Systems ECIS . 63 Kim, A., Muhn, M., amp; Nikolaev, V. 2024 . Financial Statement Analysis with Large Language Models. Chicago Booth Research Paper forthcoming ; Fama-Miller Working Paper. 64 Meta. 2024 . The Llama 3 Herd of Models. Technical Report. 65 OpenAI. 2023 . GPT-4 Technical Report. arXiv. Our Ph.D. candidate Jan Spörer presented the paper.">
        The Structure of Financial Equity Research

      </p>
    </div>
  </div>
</div>

<div class="post-excerpt-container">
  <div class="post-excerpt">
    
    
    

    
      <a href="/preview/pr-30/2025/09/05/ApertusBench.html" class="post-excerpt-image" aria-label="LLM Benchmark Evaluation - Apertus-8B">
        <img src="/preview/pr-30/images/posts/ApertusBench-Thumbnail.png" alt="LLM Benchmark Evaluation - Apertus-8B" loading="lazy" onerror="this.src = '/preview/pr-30/images/fallback.svg'; this.onerror = null;">
      </a>
    

    <div class="post-excerpt-text">
      <a href="/preview/pr-30/2025/09/05/ApertusBench.html">LLM Benchmark Evaluation - Apertus-8B</a>

      <div class="post-info">
  
    
    
      
      
        <span data-tooltip="Author">
          <i class="icon fa-solid fa-feather-pointed"></i>
          <span>götz-henrik wiegand</span>
        </span>
      
    
      
      
        <span data-tooltip="Author">
          <i class="icon fa-solid fa-feather-pointed"></i>
          <span>michael gaus</span>
        </span>
      
    
      
      
        <span data-tooltip="Author">
          <i class="icon fa-solid fa-feather-pointed"></i>
          <span>siegfried handschuh</span>
        </span>
      
    
  

  
  

  
    <span data-tooltip="Originally published on">
      <i class="icon fa-regular fa-calendar"></i>
      <span>September 05, 2025</span>
    </span>
  

  
    <span data-tooltip="Last updated on">
      <i class="icon fa-solid fa-clock-rotate-left"></i>
      <span>November 10, 2025</span>
    </span>
  
</div>


  


  <div class="tags">
    
      <a href='/preview/pr-30/blog?search="tag:%20transformers"' class="tag" data-tooltip='Show items with the tag "transformers"'>
        transformers
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20machine-learning"' class="tag" data-tooltip='Show items with the tag "machine-learning"'>
        machine-learning
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20large-language-models"' class="tag" data-tooltip='Show items with the tag "large-language-models"'>
        large-language-models
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20artificial-intelligence"' class="tag" data-tooltip='Show items with the tag "artificial-intelligence"'>
        artificial-intelligence
      </a>
    
      <a href='/preview/pr-30/blog?search="tag:%20switzerland"' class="tag" data-tooltip='Show items with the tag "switzerland"'>
        switzerland
      </a>
    
  </div>





      
      
      <p data-search="The ReleaseOn September 2, 2025, the Swiss AI Initiative a collaboration between ETH Zurich, EPFL, and the Swiss National Supercomputing Centre CSCS released the Apertus model family in two sizes: 8B and 70B parameters.The larger variant, Apertus-70B, is the first fully open model trained at this scale, developed on 4,096 GPUs using 15 trillion tokens.The models are: Trained solely on publicly available data Respectful of robots.txt exclusions retroactively Filtered for copyrighted, non-permissive, toxic, and personally identifiable content Equipped with the Goldfish loss to limit verbatim memorizationApertus supports 1,811 languages, including Swiss regional languages such as Romansh and Schwiizerdütsch. The release includes both the model weights and full reproduction artifacts for the research community. Benchmarking the ModelWe took the opportunity to benchmark the model against other models using several industry-standard benchmarks.The technical report 1 already contains comparisons with common open weight and open source models. Our goal was to: Get our own impressions of Apertus Evaluate whether we could reproduce the benchmarks presented in the reportAt this point, we highly recommend everyone take a look at the technical report for the Apertus models. It is relatively rare to find such detailed insights into state-of-the-art LLM trainings.Open Weight vs. Open ModelsIn this article, we follow the terminology used by the editors of the Technical Report and draw a clear distinction:Open Weight Models Weights and architectures are openly available Training data, scripts, and reproducibility artifacts are not published Example: Llama model family from MetaOpen Models Strive to make everything open: data, scripts, training details Aim for reproducibility and knowledge sharing in a scientific context Example: OLMO model family from the Allen Institute for AIWhy Open Models MatterAlthough open models often lag behind open weight and closed models e.g., GPT-5 from OpenAI, or Gemini in performance, they provide: Training on ethical datasets Development on a non-profit basis Opportunities for open research that is not profit-drivenDespite their current limitations in quality compared to top-tier chat applications, open models are extremely important for society. They advance the entire field of LLM Foundation Training research through transparency, reproducibility, and community-driven progress.Quicklinks to Alpertus Ressources: Technical Report: Swiss-AI Apertus Technical Report Model Hub: Hugging Face - Swiss AI Models Official Blog: Swiss AI Apertus AnnouncementImportant disclaimer: The benchmarks were created using the Apertus-8B-Instruct from Hugging Face with a subset of the leaderboard evaluations from ElutherAI s Language Model Evaluation Harness. The raw results and benchmark logs can be found on our Github repository unisg-ics-dsnlp Apertus8B-Instruct-Benchmark-Results.The benchmarks presented here are not intended to be exhaustive and are intended only to provide an overview and initial, independent assessment of the model. For more comprehensive benchmarks, please refer to the Swiss-AI Apertus Technical Report.Selected BenchmarksWe evaluated the model across four key benchmarks that test different aspects of language understanding and generation capabilities:1. IFEval Instruction Following Evaluation Task Type: 0-shot, generative Purpose: Measures the model s ability to follow specific, verifiable instructions Examples: Tasks involving word count constraints, keyword usage, formatting requirements Why it matters: Instruction-following is crucial for practical applications where models must adhere to specific user requirements2. MATH-lvl-5 Mathematical Reasoning Task Type: 4-shot, generative Purpose: Tests mathematical problem-solving capabilities using challenging level-5 problems Examples: Complex algebraic equations, calculus problems, geometric reasoning Why it matters: Mathematical reasoning demonstrates logical thinking and step-by-step problem decomposition skills3. MMLU-Pro Enhanced Multi-task Language Understanding Task Type: 5-shot, multiple-choice Purpose: Comprehensive evaluation across diverse academic and professional domains Examples: Science, history, law, medicine, engineering questions with 10 answer choices Why it matters: Broad domain knowledge is essential for general-purpose language models4. Musr Multi-step Soft Reasoning Task Type: 0-shot, multiple-choice Purpose: Evaluates complex narrative reasoning across three sub-tasks: Murder Mysteries: Logical deduction from narrative clues Object Placements: Spatial and temporal reasoning Team Allocation: Constraint satisfaction and optimization Why it matters: Tests the model s ability to maintain context and reason through multi-step scenariosWe might add more benchmarks in the future.Benchmark ResultsMost of the Math-lvl-5 and MMLU-Pro benchmark results are still missing and will be updated gradually.Performance ComparisonThe following table presents our benchmark results for Apertus-8B-Instruct compared to other open-weight and open models in similar parameter ranges: Model IFEval 0-shot 3 MMLU-Pro 5-shot 5 Math-lvl-5 4-shot 6 Musr 0-shot 4 Apertus 8B Instruct 2509 44.18 31.14 5.29 36.00 OLMo-2 1124 7B Instruct 57.67 29.02 11.71 39.81 Mistral 7B Instruct v0.3 44.73 30.56 2.95 44.33 Phi-3 Mini 4k Instruct 29.39 39.85 16.99 44.00 Qwen2.5 7B Instruct 58.04 44.72 37.08 42.59 Note: Values represent accuracy scores. Dashes - indicate pending or unavailable results.Detailed IFEval Performance BreakdownThe IFEval benchmark measures different aspects of instruction following capability. Here s the detailed breakdown across all evaluated metrics: Model Inst Level Loose Inst Level Strict Prompt Level Loose Prompt Level Strict Apertus 8B Instruct 2509 65.35 57.55 53.23 44.18 OLMo-2 1124 7B Instruct 72.42 67.51 62.85 57.67 Mistral 7B Instruct v0.3 59.59 56.35 47.13 44.73 Phi-3 Mini 4k Instruct 4k 44.36 43.41 30.50 29.39 Qwen2.5 7B Instruct 73.98 68.82 64.51 58.04 Understanding IFEval Metrics: Instruction Level: Evaluates individual instruction compliance within a prompt Loose: More lenient evaluation allowing minor deviations Strict: Rigorous evaluation requiring exact compliance Prompt Level: Evaluates overall prompt-level instruction following Loose: Partial credit for partially followed instructions Strict: All-or-nothing evaluation requiring complete instruction compliance Paper: Zhou et al. 2023: Instruction-Following Evaluation for Large Language ModelsDetailed Math Hard Model Overall Algebra Counting amp; Prob Geometry Intermediate Algebra Number Theory Prealgebra Precalculus Apertus 8B Instruct 2509 5.29 7.82 3.25 3.03 1.43 4.55 13.47 0.74 OLMo-2 1124 7B Instruct 11.71 25.41 8.94 6.82 1.43 5.84 21.76 1.48 Mistral 7B Instruct v0.3 2.95 4.89 1.63 0.00 0.71 1.30 7.77 2.22 Phi-3 Mini 4k Instruct 16.99 30.94 12.20 6.82 2.86 14.94 36.27 3.70 Qwen2.5 7B Instruct 37.08 61.89 39.84 26.52 13.21 37.01 51.81 17.04 Paper: Hendrycks et al. 2021: Measuring Mathematical Problem Solving With the MATH DatasetDetailed Musr Sub-task Performance Model Murder Mysteries Object Placements Team Allocation Overall Apertus 8B Instruct 2509 56.00 24.00 28.00 36.00 OLMo-2 1124 7B Instruct 51.60 36.72 31.20 39.81 Mistral 7B Instruct v0.3 49.00 34.00 50.00 44.33 Phi-3 Mini 4k Instruct 4k 59.00 35.00 38.00 44.00 Qwen2.5 7B Instruct 53.60 36.33 38.00 42.59 Paper: Sprague et al. 2024: MuSR: Testing the Limits of Chain-of-thought with Multistep Soft ReasoningComparison with Official BenchmarksTo validate our results, we compared our IFEval benchmark results with those reported in the Apertus Technical Report: Model Our IFEval Results Tech Report IFEval Results Difference Apertus 8B Instruct 2509 53.23 71.7 -18.47 OLMo-2-1124-7B-Instruct 57.67 71.0 -13.33 Tech Report: Post-training evaluation using prompt-level strict accuracy Table 19 Important Notes on IFEval Comparison:The performance differences between our results and the Tech Report can be attributed to: Evaluation Implementation Differences: Different prompt templates and formatting Variations in instruction parsing and evaluation criteria Potential differences in the lm-evaluation-harness versions See github.com swiss-ai lm-evaluation-harness Consistency Across Models: Both Apertus-8B-Instruct and OLMo-2-7B-Instruct show lower scores in our evaluation The consistent gap suggests systematic differences in evaluation methodology This highlights the importance of using identical evaluation settings for fair comparisons This may not necessarily mean that the results are directly comparable with the official benchmarks. However, this does not affect the comparability between the models in our benchmark.Key Observations Instruction Following IFEval : Apertus-8B-Instruct shows competitive performance at 44.18 , though it trails behind models like OLMo-2 57.67 and Qwen2.5 58.04 Mathematical Reasoning: With 5.29 on Math-lvl-5, Apertus-8B-Instruct outperforms Mistral 7B 2.95 . Multi-domain Knowledge MMLU-Pro : Achieved 31.14 accuracy across 12,032 samples Multi-step Reasoning Musr : Shows room for improvement with 36.00 overall, particularly in object placement tasks 24.00 References 1 Swiss AI Initiative. 2025 . Apertus Technical Report. GitHub Repository. https: github.com swiss-ai apertus-tech-report 2 Gao, L., Tow, J., Abbasi, B., Biderman, S., Black, S., DiPofi, A., Foster, C., Golding, L., Hsu, J., Le Noac h, A., Li, H., McDonell, K., Muennighoff, N., Ociepa, C., Phang, J., Reynolds, L., Schoelkopf, H., Skowron, A., Sutawika, L., Tang, E., Thite, A., Wang, B., Wang, K., amp; Zou, A. 2023 . A framework for few-shot language model evaluation. Zenodo. https: doi.org 10.5281 zenodo.10256836 3 Zhou, A., Yan, K., Shlapentokh-Rothman, M., Wang, H., amp; Wang, Y. 2023 . Instruction-Following Evaluation for Large Language Models. arXiv preprint. https: arxiv.org abs 2311.07911 4 Sprague, C., Gao, L., Biderman, S., amp; Sutawika, L. 2024 . MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning. arXiv preprint. https: arxiv.org abs 2310.16049 5 Wang, Y., Ma, X., Zhang, G., Ni, Y., Chandra, A., Guo, S., Ren, W., Arulraj, A., He, X., Jiang, Z., Li, T., Ku, M., Wang, K., Zhuang, A., Fan, R., Yue, X., amp; Chen, W. 2024 . MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark. arXiv preprint. https: arxiv.org abs 2406.01574 6 Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., amp; Steinhardt, J. 2021 . Measuring Mathematical Problem Solving With the MATH Dataset. arXiv preprint. https: arxiv.org abs 2103.03874">
        The Release
On September 2, 2025, the Swiss AI Initiative — a collaboration between ETH Zurich, EPFL, and the Swiss National Supercomputing Centre (CSCS) — released the Apertus model family in two sizes: 8B and 70B parameters.

      </p>
    </div>
  </div>
</div>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  <background></background>
  <dark></dark>
  <size></size>
-->

<h2 id="highlights">Highlights</h2>

<div class="feature">
  <a href="/preview/pr-30/research" class="feature-image" aria-label="Our Research">
    <img src="/preview/pr-30/images/HSG_Daten_01.png" loading="lazy" alt="Our Research" onerror="this.src = '/preview/pr-30/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Our Research</p>
    
    
<p>The DS NLP Lab has already published various papers and publications. An overview of all publications and a few highlights can be found in the publications tab.</p>

<div class="button-wrapper">
    <a class="button" href="/preview/pr-30/research" data-style="bare" data-flip="" aria-label="fa-solid fa-arrow-right">
      <i class="icon fa-solid fa-arrow-right"></i>
      
        <span>See our publications</span>
      
    </a>
  </div>


  </div>
</div>

<div class="feature" data-flip="">
  <a href="/preview/pr-30/projects" class="feature-image" aria-label="Our Projects">
    <img src="/preview/pr-30/images/cites/book_generativeK%C3%BCnstlicheIntelligenz.jpg" loading="lazy" alt="Our Projects" onerror="this.src = '/preview/pr-30/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Our Projects</p>
    
    
<p>Explore the books authored by the DS-NLP Lab team, showcasing our contributions to the fields of Artificial Intelligence, Data Science, and their societal impacts.</p>

<div class="button-wrapper">
    <a class="button" href="/preview/pr-30/books" data-style="bare" data-flip="" aria-label="fa-solid fa-arrow-right">
      <i class="icon fa-solid fa-arrow-right"></i>
      
        <span>See our recent books</span>
      
    </a>
  </div>


  </div>
</div>

<div class="feature">
  <a href="/preview/pr-30/team" class="feature-image" aria-label="Our Team">
    <img src="/preview/pr-30/images/HSG_Illustration_Lecure.png" loading="lazy" alt="Our Team" onerror="this.src = '/preview/pr-30/images/fallback.svg'; this.onerror = null;">
  </a>
  <div class="feature-text">
    
      <p class="feature-title">Our Team</p>
    
    
<p>We are a steadily growing motivated team that aims to explore the world of data science and natural language processing.</p>

<div class="button-wrapper">
    <a class="button" href="/preview/pr-30/team" data-style="bare" data-flip="" aria-label="fa-solid fa-arrow-right">
      <i class="icon fa-solid fa-arrow-right"></i>
      
        <span>Meet our team</span>
      
    </a>
  </div>


  </div>
</div>
  </section>


    </main>
    


<footer class="background" style="--image: url('/preview/pr-30/images/background.jpg')" data-dark="true" data-size="wide">
  <div>
    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://ics.unisg.ch/chairs/siegfried-handschuh-data-science-and-natural-language-processing/" data-tooltip="Website" data-style="bare" aria-label="Website">
      <i class="icon fa-solid fa-globe"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="mailto:siegfried.handschuh@unisg.ch" data-tooltip="Email" data-style="bare" aria-label="Email">
      <i class="icon fa-solid fa-envelope"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://orcid.org/0000-0002-6195-9034" data-tooltip="ORCID" data-style="bare" aria-label="ORCID">
      <i class="icon fa-brands fa-orcid"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://scholar.google.com/citations?user=zl_3HgQAAAAJ" data-tooltip="Google Scholar" data-style="bare" aria-label="Google Scholar">
      <i class="icon fa-brands fa-google"></i>
      
    </a>
  </div>


      
    <!-- | &nbsp;
  <img 
    src="/preview/pr-30/images/ICS_HSG-LogoWithWhiteBackground.png" 
    alt="Lab Logo" 
    style="max-height: 42px; width: auto; max-width: 100%; vertical-align: middle;"
  >
  &nbsp;   -->
  
</div>




  <div style="text-align: center;">
    © 2025
    by <a href="https://ics.unisg.ch/chairs/siegfried-handschuh-data-science-and-natural-language-processing/"> 
      Data Science and Natural Language Processing
    </a> at HSG
      |  
    <a href="https://github.com/unisg-ics-dsnlp">
    DS-NLP GitHub
    </a>
     
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
